<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Image Tracking with Three.js</title>
    <!-- Importar la librería de WebXR Polyfill -->
    <script src="https://cdn.jsdelivr.net/npm/webxr-polyfill@latest"></script>
    <!-- Importar la librería de WebXR de Google -->
    <script src="https://cdn.jsdelivr.net/npm/webxr-ar-module@latest"></script>
    <!-- Importar Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <h1>AR Image Tracking with Three.js</h1>
    <!-- Botón para iniciar AR -->
    <button id="start-button" onclick="startAR()">Start AR</button>
    
    <!-- Contenedor para la vista de AR -->
    <div id="ar-view"></div>
    
    <script>
        // Función para inicializar la experiencia de AR
        async function startAR() {
            try {
                // Solicitar la sesión de AR
                const session = await navigator.xr.requestSession('immersive-ar', {
                    // Requerir ARCore para la sesión de AR
                    requiredFeatures: ['local', 'hit-test'],
                    optionalFeatures: ['dom-overlay'],
                    domOverlay: { root: document.body }
                });

                // Crear el canvas para la vista de AR
                const canvas = document.createElement('canvas');
                document.body.appendChild(canvas);

                // Configurar Three.js
                const scene = new THREE.Scene();
                const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
                const renderer = new THREE.WebGLRenderer({ canvas });
                renderer.setSize(window.innerWidth, window.innerHeight);

                // Configurar la posición de la cámara para coincidir con la cámara de la sesión de AR
                const xrViewerPose = await session.requestFrameOfReference('viewer');
                const viewerSpace = await session.requestAnimationFrame((time, frame) => {
                    const pose = frame.getViewerPose(xrViewerPose);
                    if (pose) {
                        const viewerPose = pose.views[0];
                        camera.matrix.fromArray(viewerPose.transform.matrix);
                        camera.matrix.decompose(camera.position, camera.quaternion, camera.scale);
                    }
                });

                // Crear la imagen a rastrear
                const imageToTrack = new XRImageTrackingTarget('qr-117.png');

                // Configurar el rastreador de imágenes
                const imageTracker = await session.createImageTracker(imageToTrack);

                // Cargar el modelo 3D
                const loader = new THREE.GLTFLoader();
                loader.load('model_61a_-_bottlenose_dolphin-2.glb', function (gltf) {
                    scene.add(gltf.scene);
                });

                // Añadir evento de rastreo de imágenes
                imageTracker.addEventListener('imagetracking', event => {
                    const trackedImage = event.frame.getTrackedImage(imageToTrack);
                    if (trackedImage) {
                        // Actualizar la posición del modelo 3D para que coincida con la posición de la imagen rastreada
                        // Esto implicaría ajustar la posición y la orientación del modelo en función de la posición y la orientación de la imagen rastreada
                    }
                });

                // Función para el bucle de renderizado
                function animate() {
                    requestAnimationFrame(animate);
                    // Renderizar la escena Three.js
                    renderer.render(scene, camera);
                }
                animate();

            } catch (error) {
                console.error('Error al iniciar la experiencia de AR:', error);
            }
        }
    </script>
</body>
</html>

