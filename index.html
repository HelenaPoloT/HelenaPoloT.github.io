<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Image Tracking with Unity Model</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: black;
        }

        canvas {
            width: 100%;
            height: 100%;
            display: block;
        }
    </style>
</head>
<body>
    <script src="https://cdn.jsdelivr.net/npm/webxr-polyfill@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/webxr-ar-module@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@google/model-viewer@1/dist/model-viewer.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', async () => {
            try {
                // Solicitar la sesión de AR
                const session = await navigator.xr.requestSession('immersive-ar', {
                    requiredFeatures: ['hit-test', 'image-tracking']
                });

                // Crear la capa base para renderizar la escena de AR
                const layer = new XRWebGLLayer(session, new THREE.WebGLRenderer().getContext());

                // Configurar la capa base
                session.updateRenderState({
                    baseLayer: layer
                });

                // Crear la escena de Three.js
                const scene = new THREE.Scene();

                // Obtener el entorno de referencia local
                const referenceSpace = await session.requestReferenceSpace('local');

                // Obtener el rastreador de imágenes
                const imageTracker = await session.requestImageTracker();

                // Añadir la imagen a rastrear
                const imageTarget = new XRImageTrackingTarget("qr-117.png");
                imageTracker.addTarget(imageTarget);

                // Cargar el modelo desde Unity en formato glTF
                const loader = new THREE.GLTFLoader();
                loader.load('model_61a_-_bottlenose_dolphin-2.glb', function (gltf) {
                    // Ajustar la escala y posición del modelo
                    gltf.scene.scale.set(0.1, 0.1, 0.1);
                    gltf.scene.position.set(0, 0, -0.5);

                    // Añadir el modelo a la escena
                    scene.add(gltf.scene);
                });

                // Bucle de renderizado
                function render(timestamp, xrFrame) {
                    // Obtener la pose del visor
                    const pose = xrFrame.getViewerPose(referenceSpace);
                    if (pose) {
                        // Actualizar la posición y orientación del modelo cuando la imagen sea rastreada
                        const trackedImage = xrFrame.getTrackedImage(imageTarget);
                        if (trackedImage) {
                            // Obtener la matriz de transformación de la imagen rastreada
                            const modelMatrix = trackedImage.getModelMatrix();
                            
                            // Actualizar la posición y orientación del modelo en la escena de Three.js
                            gltf.scene.matrix.fromArray(modelMatrix);
                            gltf.scene.matrix.decompose(gltf.scene.position, gltf.scene.quaternion, gltf.scene.scale);
                        }
                    }

                    // Renderizar la escena
                    session.requestAnimationFrame(render);
                }

                session.requestAnimationFrame(render);
            } catch (error) {
                console.error('Error al iniciar la experiencia de AR:', error);
            }
        });
    </script>
</body>
</html>


